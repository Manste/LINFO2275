{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3aGlfSG2dkuO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "LIMIT = 10\n",
        "class Dataset:\n",
        "    def __init__(self, LIMIT=10, dir_path=\"drive/MyDrive/Datasets\"):\n",
        "        self.dataset = [[[] for _ in range(10)] for _ in range(10)]\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        limit_the_search = [j for i in range(10) for k in range(10) for j in range(i*100+(k*10)+1, i*100+(k*10)+LIMIT+1)]\n",
        "        for i in limit_the_search:\n",
        "          filepath = \"{}/{}.txt\".format(dir_path, i)\n",
        "          try:\n",
        "              lines = [line.strip() for line in open(filepath, \"r\")]\n",
        "              class_id =  int(lines[1][len(lines[1]) - 1])\n",
        "              user_id = int(lines[2][len(lines[2]) - 1])\n",
        "              user_data = []\n",
        "              for i, line in enumerate(lines[5:]):\n",
        "                  if line:\n",
        "                      user_data.append(list(map(float, line.split(',')))[0:3])\n",
        "              self.dataset[user_id - 1][class_id - 1].append(user_data) \n",
        "              self.data.append(user_data)\n",
        "              self.labels.append(class_id)\n",
        "          except IOError as e:\n",
        "              print(\"Unable to read dataset file {}!\\n\".format(filepath))\n",
        "\n",
        "    def get_user(self, index):\n",
        "        \"\"\"Returns an array containing all the data saved for the user <<index>>\"\"\"\n",
        "        return len(self.data[index])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WBKsRAWddykZ"
      },
      "outputs": [],
      "source": [
        "data = Dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCGL5fwvEI_U"
      },
      "source": [
        "# K-Nearest Neighbors & DTW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8Ii0NDCY6U1P"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import mode\n",
        "from joblib import Parallel, delayed\n",
        "from numba import njit, prange\n",
        "from numba.typed import List\n",
        "\n",
        "@njit()\n",
        "def distance(x, y):\n",
        "  dist = 0.\n",
        "  for di in range(len(x)):\n",
        "      diff = (x[di] - y[di])\n",
        "      dist += diff * diff\n",
        "  return dist\n",
        "\n",
        "@njit(nogil=True)\n",
        "def dtw_distance(time_serie1, time_serie2):\n",
        "  l1, l2 = len(time_serie1), len(time_serie2)\n",
        "  cost_matrix = np.full((l1 + 1, l2 + 1), np.inf)\n",
        "  # Initialize the first cell\n",
        "  cost_matrix[0, 0] = 0. \n",
        "  # populatte the cost matrix within window\n",
        "  for i in range(l1):\n",
        "    for j in range(l2):\n",
        "      cost_matrix[i+1, j+1] = distance(List(time_serie1[i]), List(time_serie2[j])) \n",
        "      cost_matrix[i+1, j+1] += min(cost_matrix[i, j +1], cost_matrix[i+1, j], cost_matrix[i, j])\n",
        "  return np.sqrt(cost_matrix[1:, 1:])[-1, -1]\n",
        "\n",
        "class KNN_DTW:\n",
        "  \"\"\"\n",
        "  This class is a classifier using DTW as distance measure between pairs of time series data\n",
        "  \"\"\"\n",
        "  def __init__(self, n_neighbors=1, warping_window=50):\n",
        "    self.n_neighbors = n_neighbors\n",
        "    self.warping_window = warping_window\n",
        "\n",
        "  def fit(self, x, labels):\n",
        "    self.x = np.array(x)\n",
        "    self.labels = np.array(labels)\n",
        "  \n",
        "\n",
        "  def predict(self, x):\n",
        "    dist_matrix = np.zeros((x.shape[0], self.x.shape[0]))\n",
        "    matrix = Parallel(n_jobs=-1, prefer=\"threads\", verbose=0)(\n",
        "            delayed(dtw_distance)(\n",
        "                List(x[i]), List(self.x[j])\n",
        "            )\n",
        "            for i in range(len(x)) for j in range(len(self.x))\n",
        "        )\n",
        "    dist_matrix = np.array(matrix).reshape((len(x), -1))\n",
        "    # the index of the k nearest neighbors\n",
        "    indexes = dist_matrix.argsort()[:, :self.n_neighbors]\n",
        "    # identifiers the neigbors\n",
        "    labels = self.labels[indexes]\n",
        "    # get the majority votes\n",
        "    predictions = mode(labels, axis=1)[0]\n",
        "    #print(predictions)\n",
        "    return predictions\n",
        "\n",
        "# Validation function\n",
        "def test(user_id, dataset, labels, model, LIMIT=100):\n",
        "  # split the dataset\n",
        "  indexes = range(user_id*LIMIT, user_id*LIMIT+LIMIT+1)\n",
        "  train_set = np.delete(dataset, indexes)\n",
        "  train_labels = np.delete(labels, indexes)\n",
        "  test_labels = labels[indexes]\n",
        "  test_set = dataset[indexes]\n",
        "  # Prediction\n",
        "  model.fit(train_set, train_labels)\n",
        "  predictions = model.predict(test_set)\n",
        "  return accuracy_score(test_labels, predictions)\n",
        "\n",
        "\n",
        "def validation(dataset, labels, model, LIMIT=100):\n",
        "  dataset = np.array(dataset)\n",
        "  labels = np.array(labels)\n",
        "  accuracies = []\n",
        "  for user_id in range(10):\n",
        "    accuracies.append(test(user_id, dataset, labels, model, LIMIT))\n",
        "    print(\"The user score {}: {}\".format(user_id+1, accuracies[-1]))\n",
        "  return accuracies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P5P5A3p3u9V",
        "outputId": "0f9c53ac-dbb0-4115-c865-bd00c96771fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/numba/typed/typedlist.py:66: NumbaPendingDeprecationWarning: \n",
            "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'item' of function 'impl_append.<locals>.impl'.\n",
            "\n",
            "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
            "\n",
            "File \"../usr/local/lib/python3.7/dist-packages/numba/typed/listobject.py\", line 596:\n",
            "\n",
            "    def impl(l, item):\n",
            "    ^\n",
            "\n",
            "  l.append(item)\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/ir_utils.py:2031: NumbaPendingDeprecationWarning: \n",
            "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'item' of function '_append'.\n",
            "\n",
            "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
            "\n",
            "File \"../usr/local/lib/python3.7/dist-packages/numba/typed/typedlist.py\", line 65:\n",
            "@njit\n",
            "def _append(l, item):\n",
            "^\n",
            "\n",
            "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n"
          ]
        }
      ],
      "source": [
        "model = KNN_DTW(1)\n",
        "accuracies = validation(np.array(data.data).T, data.labels, model, 100)\n",
        "accuracies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J21789JGZb6G"
      },
      "source": [
        "# Using another library"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "datamining2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}